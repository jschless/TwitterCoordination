{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import datetime \n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = '/pool001/jschless/kiran-data/kiran-data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in Friends Data\n",
    "Store it in a dictionary of the form {username: set(friends of username)} \n",
    "\n",
    "Takes 40 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.6 s, sys: 2.86 s, total: 53.5 s\n",
      "Wall time: 53.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "friends_dict = (\n",
    "    pd.read_csv(os.path.join(DATA_DIR, 'FRIENDS.txt'),  # loading data\n",
    "                sep='\\t', names=['user', 'friend'])\n",
    "        .groupby('user') # group by the user \n",
    "        .apply(lambda x: set(x.friend)) # get set of all friends\n",
    "        .to_dict() # convert it to a python dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Convert Tweet Data into Pipeline Format\n",
    "For each hashtag, we need to find who saw a tweet from a friend using the hashtag before participating\n",
    "\n",
    "Also, create mapping of user ids to user names\n",
    "\n",
    "Takes 1.5 minutes to run\n",
    "\n",
    "__Errors: 540 of the tweets do not properly parse as JSONs. Not sure what happened, but different issues each time. Was such a small number I just ignored it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# errors 540\n",
      "CPU times: user 1min 28s, sys: 3.56 s, total: 1min 31s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# only store the following tweet columns, saves time and memory\n",
    "columns_needed = set(['author_id', 'screen_name', 'created_at', 'date', 'id', 'text', 'trend', 'trend_date'])\n",
    "\n",
    "tweet_dict = {}\n",
    "name_to_id = {}\n",
    "id_to_name = {}\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'TWEETINFO.txt'), 'r') as f:\n",
    "    errors = 0\n",
    "    for i, line in enumerate(f):\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            id_to_name[tweet['user']['id']] = tweet['user']['screen_name']\n",
    "            name_to_id[tweet['user']['screen_name']] = tweet['user']['id']  \n",
    "            \n",
    "            filtered_tweet = {k:v for k,v in tweet.items() if k in columns_needed}\n",
    "            tweet_dict[tweet['id']] = filtered_tweet\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "\n",
    "print(\"# errors\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load ht mapping file\n",
    "ht_mapping = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, 'hashtag_mapping.txt'), \n",
    "    sep='\\t', \n",
    "    header=None, \n",
    "    index_col=1).to_dict()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Dictionary of Hashtag Tweets\n",
    "\n",
    "__Errors: 21k of the tweets had issues. The tweet_id did not exist in the TWEETINFO.txt file. Many of them appear to be private accounts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 418/418 [00:39<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# errors 20961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of the form {hashtag: list[tweets using hashtag]}\n",
    "campaigns = {}\n",
    "errors = 0\n",
    "for ht_id in tqdm(os.listdir(os.path.join(DATA_DIR, 'hashtag_data'))):\n",
    "    ht = ht_mapping[int(ht_id)]\n",
    "    tweets = []\n",
    "    with open(os.path.join(DATA_DIR, 'hashtag_data', ht_id)) as f:\n",
    "        for link in f:\n",
    "            tokens = link.split('/')\n",
    "            tweet_id = int(tokens[-1])\n",
    "\n",
    "            try: \n",
    "                tweet = tweet_dict[tweet_id]\n",
    "                tweet['author'] = tokens[3]\n",
    "                tweet['author_id'] = name_to_id.get(tokens[3], -1)\n",
    "                tweet['trend'] = ht\n",
    "                if isinstance(tweet['created_at'], str):\n",
    "                    # if the created at is not a date, convert it\n",
    "                    tweet['created_at'] = datetime.datetime.strptime(tweet['created_at'], \n",
    "                                                                     '%a %b %d %H:%M:%S +0000 %Y')\n",
    "                tweets.append(tweet)\n",
    "            except Exception as e:\n",
    "#                 print(e, link)\n",
    "                errors += 1\n",
    "    campaigns[ht] = tweets    \n",
    "print('# errors', errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration with Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TURKEY_DIR = '/pool001/jschless/turkish_astroturfing'\n",
    "\n",
    "df = pd.read_csv(os.path.join(TURKEY_DIR, 'trend_tweets.csv'),\n",
    "                parse_dates=['date', 'trend_date', 'created_at'])\n",
    "\n",
    "old_campaigns = df.groupby(\"trend\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "del df \n",
    "\n",
    "# fill in missing author names from Tugrulcan's data\n",
    "for ht, tweets in old_campaigns.items():\n",
    "    for tweet in tweets:\n",
    "        tweet['author'] = id_to_name.get(tweet['author_id'], 'missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge original data with the new data\n",
    "for ht in campaigns.keys():\n",
    "    campaigns[ht] += old_campaigns.get(ht, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 418/418 [01:10<00:00,  5.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for ht, tweets in tqdm(campaigns.items()):\n",
    "    tweeted = set()\n",
    "    sorted_tweets = sorted(tweets, key=lambda x: x['created_at'])\n",
    "    for tweet in sorted_tweets:\n",
    "        # take the intersection of the set of friends and the set of people who have already used the hashtag\n",
    "        # if this is non empty, they are unexposed\n",
    "        tweet['exposed'] = len(friends_dict.get(tweet['author'], set()).intersection(tweeted)) != 0\n",
    "        tweeted.add(tweet['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointing\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'campaigns.pkl'), 'wb') as f:\n",
    "    pickle.dump(campaigns, f)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR, 'campaigns.pkl'), 'rb') as f:\n",
    "    campaigns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 57s, sys: 10.5 s, total: 3min 7s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for ht, tweets in campaigns.items():\n",
    "    df = df.append(pd.DataFrame.from_records(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>trend</th>\n",
       "      <th>exposed</th>\n",
       "      <th>date</th>\n",
       "      <th>trend_date</th>\n",
       "      <th>tweet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-02 14:05:16</td>\n",
       "      <td>1256585550796148738</td>\n",
       "      <td>#MilliGazeteOkuyorum #SesimizBir #Cumartesi #D...</td>\n",
       "      <td>GunesliGuzel</td>\n",
       "      <td>293656352</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-18 17:38:31</td>\n",
       "      <td>1196482833696645120</td>\n",
       "      <td>Kamuda çalışan üniversiteli işçiler memur stat...</td>\n",
       "      <td>yaprakergen</td>\n",
       "      <td>325766266</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-11 17:02:57</td>\n",
       "      <td>1193937167007068160</td>\n",
       "      <td>@MemurSenKonf Üniversite mezunu 4D'li işçiler ...</td>\n",
       "      <td>Erdemakkusss</td>\n",
       "      <td>965200054352076800</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-11 15:21:30</td>\n",
       "      <td>1193911634013630466</td>\n",
       "      <td>@_aliyalcin_ Üniversite mezunu 4D'li işçiler o...</td>\n",
       "      <td>Erdemakkusss</td>\n",
       "      <td>965200054352076800</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-11 15:21:17</td>\n",
       "      <td>1193911580230062080</td>\n",
       "      <td>@SabahMemurlar Üniversite mezunu 4D'li işçiler...</td>\n",
       "      <td>Erdemakkusss</td>\n",
       "      <td>965200054352076800</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at                   id  \\\n",
       "0 2020-05-02 14:05:16  1256585550796148738   \n",
       "1 2019-11-18 17:38:31  1196482833696645120   \n",
       "2 2019-11-11 17:02:57  1193937167007068160   \n",
       "3 2019-11-11 15:21:30  1193911634013630466   \n",
       "4 2019-11-11 15:21:17  1193911580230062080   \n",
       "\n",
       "                                                text        author  \\\n",
       "0  #MilliGazeteOkuyorum #SesimizBir #Cumartesi #D...  GunesliGuzel   \n",
       "1  Kamuda çalışan üniversiteli işçiler memur stat...   yaprakergen   \n",
       "2  @MemurSenKonf Üniversite mezunu 4D'li işçiler ...  Erdemakkusss   \n",
       "3  @_aliyalcin_ Üniversite mezunu 4D'li işçiler o...  Erdemakkusss   \n",
       "4  @SabahMemurlar Üniversite mezunu 4D'li işçiler...  Erdemakkusss   \n",
       "\n",
       "            author_id                        trend  exposed date trend_date  \\\n",
       "0           293656352  #ÜniversiteliİşçilereAdalet    False  NaT        NaT   \n",
       "1           325766266  #ÜniversiteliİşçilereAdalet    False  NaT        NaT   \n",
       "2  965200054352076800  #ÜniversiteliİşçilereAdalet     True  NaT        NaT   \n",
       "3  965200054352076800  #ÜniversiteliİşçilereAdalet     True  NaT        NaT   \n",
       "4  965200054352076800  #ÜniversiteliİşçilereAdalet     True  NaT        NaT   \n",
       "\n",
       "  tweet_type  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trending Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tr_start</th>\n",
       "      <th>tr_end</th>\n",
       "      <th>vol</th>\n",
       "      <th>max_rank</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>attack</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-27 06:14:01</td>\n",
       "      <td>2019-06-27 08:09:03</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0 days 01:55:02.000000000</td>\n",
       "      <td>False</td>\n",
       "      <td>\"Maçka\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-20 18:38:28</td>\n",
       "      <td>2019-06-20 22:24:33</td>\n",
       "      <td>14474</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 03:46:05.000000000</td>\n",
       "      <td>True</td>\n",
       "      <td>#1200ÜcretliAtamasıHaktır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-20 22:29:29</td>\n",
       "      <td>2019-06-20 23:59:37</td>\n",
       "      <td>14495</td>\n",
       "      <td>6</td>\n",
       "      <td>0 days 01:30:08.000000000</td>\n",
       "      <td>False</td>\n",
       "      <td>#1200ücretliatamasıhaktır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-15 04:12:22</td>\n",
       "      <td>2019-07-15 13:02:52</td>\n",
       "      <td>118537</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 08:50:30.000000000</td>\n",
       "      <td>False</td>\n",
       "      <td>#15TEMMUZDESTANI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-15 13:32:57</td>\n",
       "      <td>2019-07-15 13:47:54</td>\n",
       "      <td>124473</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 00:14:57.000000000</td>\n",
       "      <td>False</td>\n",
       "      <td>#15TEMMUZDESTANI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tr_start              tr_end     vol  max_rank  \\\n",
       "0 2019-06-27 06:14:01 2019-06-27 08:09:03      -1         8   \n",
       "1 2019-06-20 18:38:28 2019-06-20 22:24:33   14474         1   \n",
       "2 2019-06-20 22:29:29 2019-06-20 23:59:37   14495         6   \n",
       "3 2019-07-15 04:12:22 2019-07-15 13:02:52  118537         1   \n",
       "4 2019-07-15 13:32:57 2019-07-15 13:47:54  124473         1   \n",
       "\n",
       "                    lifetime  attack                      trend  \n",
       "0  0 days 01:55:02.000000000   False                    \"Maçka\"  \n",
       "1  0 days 03:46:05.000000000    True  #1200ÜcretliAtamasıHaktır  \n",
       "2  0 days 01:30:08.000000000   False  #1200ücretliatamasıhaktır  \n",
       "3  0 days 08:50:30.000000000   False           #15TEMMUZDESTANI  \n",
       "4  0 days 00:14:57.000000000   False           #15TEMMUZDESTANI  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TURKEY_DIR = '/pool001/jschless/turkish_astroturfing'\n",
    "\n",
    "trend_file = 'trend_analysis_top10.csv' \n",
    "#trend_file = 'world_trend_analysis_top10.csv'\n",
    "\n",
    "trending_info = pd.read_csv(os.path.join(TURKEY_DIR, trend_file),\n",
    "                           parse_dates=['tr_start', 'tr_end', 'lifetime', 'date'])\n",
    "\n",
    "trending_info['trend'] = trending_info.keyword\n",
    "\n",
    "trending_info = trending_info.drop(columns=['date', 'id', 'keyword'])\n",
    "\n",
    "trending_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trending_info['time_trending'] = trending_info.tr_end - trending_info.tr_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tr_start</th>\n",
       "      <th>tr_end</th>\n",
       "      <th>vol</th>\n",
       "      <th>max_rank</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>attack</th>\n",
       "      <th>trend</th>\n",
       "      <th>time_trending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>2019-07-05 17:32:49</td>\n",
       "      <td>2019-07-05 18:12:53</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 00:40:04.000000000</td>\n",
       "      <td>True</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>00:40:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>2019-07-05 18:22:52</td>\n",
       "      <td>2019-07-05 19:42:43</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0 days 01:19:51.000000000</td>\n",
       "      <td>True</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>01:19:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>2019-07-05 19:52:41</td>\n",
       "      <td>2019-07-05 20:57:40</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>0 days 01:04:59.000000000</td>\n",
       "      <td>True</td>\n",
       "      <td>#ÜniversiteliİşçilereAdalet</td>\n",
       "      <td>01:04:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tr_start              tr_end  vol  max_rank  \\\n",
       "1405 2019-07-05 17:32:49 2019-07-05 18:12:53   -1         1   \n",
       "1406 2019-07-05 18:22:52 2019-07-05 19:42:43   -1         4   \n",
       "1407 2019-07-05 19:52:41 2019-07-05 20:57:40   -1         5   \n",
       "\n",
       "                       lifetime  attack                        trend  \\\n",
       "1405  0 days 00:40:04.000000000    True  #ÜniversiteliİşçilereAdalet   \n",
       "1406  0 days 01:19:51.000000000    True  #ÜniversiteliİşçilereAdalet   \n",
       "1407  0 days 01:04:59.000000000    True  #ÜniversiteliİşçilereAdalet   \n",
       "\n",
       "     time_trending  \n",
       "1405      00:40:04  \n",
       "1406      01:19:51  \n",
       "1407      01:04:59  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_info.query('trend == \"#ÜniversiteliİşçilereAdalet\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol</th>\n",
       "      <th>max_rank</th>\n",
       "      <th>time_trending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.787000e+03</td>\n",
       "      <td>3787.000000</td>\n",
       "      <td>3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.199098e+04</td>\n",
       "      <td>5.490890</td>\n",
       "      <td>0 days 01:52:58.148930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.240535e+05</td>\n",
       "      <td>3.045631</td>\n",
       "      <td>0 days 02:21:39.023816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0 days 00:10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0 days 01:05:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0 days 02:41:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.382066e+06</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0 days 22:15:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                vol     max_rank           time_trending\n",
       "count  3.787000e+03  3787.000000                    3787\n",
       "mean   2.199098e+04     5.490890  0 days 01:52:58.148930\n",
       "std    1.240535e+05     3.045631  0 days 02:21:39.023816\n",
       "min   -1.000000e+00     1.000000         0 days 00:00:00\n",
       "25%   -1.000000e+00     3.000000         0 days 00:10:01\n",
       "50%   -1.000000e+00     6.000000         0 days 01:05:01\n",
       "75%   -1.000000e+00     8.000000         0 days 02:41:39\n",
       "max    3.382066e+06    10.000000         0 days 22:15:08"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Tugrulcan's classifier for lexicon tweets\n",
    "\n",
    "import emoji\n",
    "import string\n",
    "\n",
    "def give_emoji_free_text(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def lexicon_classifier(line, trend):\n",
    "    line = give_emoji_free_text(line)\n",
    "    line = line.replace(trend, '')\n",
    "    line = line.replace('  ', ' ')\n",
    "\n",
    "    line = line.strip()\n",
    "\n",
    "    if (len(line) == 0):\n",
    "        return False\n",
    "\n",
    "    if (line[0].isupper()):\n",
    "        return False\n",
    "\n",
    "    invalidChars = set(string.punctuation.replace(\"(\", \"…\").replace(\")\", \"...\").replace('.', \".\").replace('.', '.'))\n",
    "    invalidChars = invalidChars.union(set([\"%d\" % i for i in range(0,10)])) # added numbers\n",
    "\n",
    "    if any(char in invalidChars for char in line):\n",
    "        return False\n",
    "\n",
    "    tokens = line.split(' ')\n",
    "    if (len(tokens) > 10 or len(tokens) < 3):\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 42s, sys: 9.44 s, total: 10min 51s\n",
      "Wall time: 10min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "mega_df = df.merge(trending_info, on='trend')\n",
    "mega_df[\"time_since_trending\"] = mega_df.created_at - mega_df.tr_start\n",
    "mega_df[\"time_since_trending\"] = mega_df.time_since_trending.apply(lambda x: int(x.total_seconds() / 60))\n",
    "mega_df[\"lexicon\"] = mega_df.apply(lambda x: lexicon_classifier(x.text, x.trend), axis=1)\n",
    "mega_df['follower_data'] = mega_df.author.apply(lambda x: x in friends_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save now, after a lot of the heavy lifting is done \n",
    "mega_df.to_pickle(os.path.join(DATA_DIR, 'mega_df.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "gt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
